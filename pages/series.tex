\twocolumn[
\begin{center}
\textbf{\Large Series Solutions for ODEs}
\end{center}
\vspace{4pt}]

%----------------------------------------------
\textbf{Power Series Method (Ordinary Points)}

Recall that a power series is an expansion of the form
\[
y(x)=\sum_{n=0}^{\infty} a_n (x-x_0)^n .
\]
For a linear differential equation
\[
y'' + p(x)y' + q(x)y = r(x),
\]
if \(p(x), q(x), r(x)\) are analytic at \(x_0\), then the solution is also analytic at \(x_0\).
This allows us to represent the solution as a power series and reduce the differential equation to an algebraic recurrence relation for the coefficients \(a_n\). To solve such equations, we need to follow these steps:



\textbf{1. Assume:} $y = \sum_{n=0}^{\infty} a_n x^n$

$y' = \sum_{n=1}^{\infty} n a_n x^{n-1}$, \quad $y'' = \sum_{n=2}^{\infty} n(n-1) a_n x^{n-2}$

\textbf{2.} Shift indices to equalize powers of $x^n$

\textbf{3.} Write out and equalize with RHS

\textbf{4.} Develop recurrence for $a_n$, $a_{n+1}$, or $a_{n+2}$

\textbf{5.} Solution: $y(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \cdots$

\textbf{Common Series:}

$e^{ax} = \sum \frac{(ax)^n}{n!}$, \quad $\sin x = \sum (-1)^n \frac{x^{2n+1}}{(2n+1)!}$, \quad $\cos x = \sum (-1)^n \frac{x^{2n}}{(2n)!}$

\textbf{Initial Conditions:} If $y(0), y'(0)$ given, verify by taking derivatives and substituting.

Taylor form: $y = \sum \frac{y^{(n)}(0)}{n!} x^n$

\vspace{6pt}
%----------------------------------------------
\textbf{Frobenius Method (Singular Points)}

When \(p(x)\) or \(q(x)\) contains singular terms such as \(\tfrac{1}{x}\) or \(\tfrac{1}{x^2}\), the standard power series method generally fails because the solution need not be analytic at the expansion point.

A point \(x_0\) is called a \textbf{regular singular point} if \((x-x_0)p(x)\) and \((x-x_0)^2 q(x)\) are analytic at \(x_0\). 
Although the coefficients are singular, the differential equation retains enough structure to admit solutions of a generalized power series form.

In this case, the appropriate technique is the \textbf{Frobenius Method}, which extends the power series approach to handle regular singular points.


\textbf{Assume:} $y = \sum_{n=0}^{\infty} a_n (x-x_0)^{n+r}$ where $r$ is found from the \textbf{indicial equation}.

$y' = \sum_{n=0}^{\infty} (n+r) a_n (x-x_0)^{n+r-1}$

$y'' = \sum_{n=0}^{\infty} (n+r)(n+r-1) a_n (x-x_0)^{n+r-2}$

Substitute into ODE $\to$ indicial equation for $r$ arises from the lowest power coefficient. The roots $r_1, r_2$ (with $r_1 \geq r_2$) determine the form of solutions.

\vspace{6pt}
%----------------------------------------------
\textbf{Cases for Indicial Roots}

\textbf{Case I: Distinct roots, $r_1 - r_2 \notin \mathbb{Z}$}

$y_1 = x^{r_1} \sum a_n x^n$, \quad $y_2 = x^{r_2} \sum b_n x^n$

Both solutions found directly by substitution.

\textbf{Case II: Equal roots, $r_1 = r_2 = r$}

$y_1 = x^{r} \sum a_n x^n$

$y_2 = y_1 \ln x + x^{r} \sum c_n x^n$

\textbf{Abel's Formula:} Given $y_1$, find $y_2$ via reduction of order:
\[
y_2 = y_1 \int \frac{e^{-\int P(x)\,dx}}{[y_1]^2} \, dx
\]
where $P(x)$ is from the normalized form $y'' + P(x)y' + Q(x)y = 0$.

\textbf{Case III: Roots differ by integer, $r_1 - r_2 = k \in \mathbb{Z}^+$}

$y_1 = x^{r_1} \sum a_n x^n$ (use larger root)

For $y_2$: Try the second root $r_2$ directly as in Case I. This may work and give a valid second solution.

If the recurrence collapses (division by zero), then use:
\[
y_2 = C y_1 \ln x + x^{r_2} \sum_{n=0}^{\infty} c_n x^n
\]
where $C$ is a constant (possibly zero) determined by substitution.

\vspace{6pt}
%----------------------------------------------
\textbf{Constructing the Solution}

After finding the series coefficients, write:
\[
y(x) = x^r \left[ a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \cdots \right]
\]
Factor out common terms and identify known functions (exponentials, trig functions, Bessel functions, etc.) when possible.

\vspace{6pt}
%----------------------------------------------
\textbf{Bessel's Functions}
Bessel Functions are solutions to Bessel equations with the form:

$x^2 y'' + xy' + (x^2 - \nu^2)y = 0$


\begin{wrapfigure}{r}{0.25\textwidth}
    \centering
    \vspace{-10pt}
    \includegraphics[width=0.24\textwidth]{figures/output.png}
    \caption*{\scriptsize $J_0(u_{04}r)$ on unit disk}
    \vspace{-5pt}
\end{wrapfigure}

They can be considered as a special case of the Frobenius solution when $r=n$ and they arise naturally when solving PDEs (heat, wave, Laplace) in cylindrical or spherical coordinates.


Bessel function of the first kind:
\[
J_\nu(x) = \sum_{n=0}^{\infty} \frac{(-1)^n}{n! \, \Gamma(n+\nu+1)} \left(\frac{x}{2}\right)^{2n+\nu}
\]

\textbf{Case 1:} $\nu \neq$ integer — $J_\nu$ and $J_{-\nu}$ are linearly independent:
\[
y = c_1 J_\nu(x) + c_2 J_{-\nu}(x)
\]

\textbf{Case 2:} $\nu = n$ (integer) — $J_{-n} = (-1)^n J_n$, need Bessel function of the second kind:
\[
y = c_1 J_n(x) + c_2 Y_n(x)
\]
where $Y_n(x) = \displaystyle\lim_{\nu \to n} \frac{J_\nu(x)\cos(\nu\pi) - J_{-\nu}(x)}{\sin(\nu\pi)}$

\textbf{Note:} $J_n(0)$ is bounded; $Y_n(0) \to -\infty$. For domains including origin, set $c_2 = 0$.